{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 786363 entries, 0 to 786362\n",
      "Data columns (total 29 columns):\n",
      " #   Column                    Non-Null Count   Dtype  \n",
      "---  ------                    --------------   -----  \n",
      " 0   accountNumber             786363 non-null  int64  \n",
      " 1   customerId                786363 non-null  int64  \n",
      " 2   creditLimit               786363 non-null  int64  \n",
      " 3   availableMoney            786363 non-null  float64\n",
      " 4   transactionDateTime       786363 non-null  object \n",
      " 5   transactionAmount         786363 non-null  float64\n",
      " 6   merchantName              786363 non-null  object \n",
      " 7   acqCountry                786363 non-null  object \n",
      " 8   merchantCountryCode       786363 non-null  object \n",
      " 9   posEntryMode              786363 non-null  object \n",
      " 10  posConditionCode          786363 non-null  object \n",
      " 11  merchantCategoryCode      786363 non-null  object \n",
      " 12  currentExpDate            786363 non-null  object \n",
      " 13  accountOpenDate           786363 non-null  object \n",
      " 14  dateOfLastAddressChange   786363 non-null  object \n",
      " 15  cardCVV                   786363 non-null  int64  \n",
      " 16  enteredCVV                786363 non-null  int64  \n",
      " 17  cardLast4Digits           786363 non-null  int64  \n",
      " 18  transactionType           786363 non-null  object \n",
      " 19  echoBuffer                786363 non-null  object \n",
      " 20  currentBalance            786363 non-null  float64\n",
      " 21  merchantCity              786363 non-null  object \n",
      " 22  merchantState             786363 non-null  object \n",
      " 23  merchantZip               786363 non-null  object \n",
      " 24  cardPresent               786363 non-null  bool   \n",
      " 25  posOnPremises             786363 non-null  object \n",
      " 26  recurringAuthInd          786363 non-null  object \n",
      " 27  expirationDateKeyInMatch  786363 non-null  bool   \n",
      " 28  isFraud                   786363 non-null  bool   \n",
      "dtypes: bool(3), float64(3), int64(6), object(17)\n",
      "memory usage: 158.2+ MB\n",
      "None\n",
      "Columns that will be dropped: ['echoBuffer' 'merchantCity' 'merchantState' 'merchantZip' 'posOnPremises'\n",
      " 'recurringAuthInd' 'transactionDtYear' 'cvvMismatchScore']\n",
      "        transactionType transactionAmount                       \n",
      "                                    count nunique   min      max\n",
      "0  ADDRESS_VERIFICATION             20169       1  0.00     0.00\n",
      "1              PURCHASE            745193   66011  0.00  2011.54\n",
      "2              REVERSAL             20303   14450  0.00  1435.64\n",
      "3                   UNK               698     685  0.11  1135.64\n",
      "The dataset contains 1.6% of fraudulent cases.\n",
      "cardPresent  expirationDateKeyInMatch  isFraud\n",
      "0            0                         0          424533\n",
      "1            0                         0          348383\n",
      "0            0                         1            8962\n",
      "1            0                         1            3442\n",
      "             1                         0            1030\n",
      "                                       1              13\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\Desktop\\Vikrant\\Github_Repositories\\Credit_Card_Fraud_Detection\\utils\\util_functions.py:266: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  nvalues_categorical_df = main_df[categorical_cols].nunique()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ordinal-encoding posEntryMode instead of OHE...\n",
      "Not using one-hot-encoding for \"posEntryMode\" since even a 5-valued categorical feature requires 55GB!\n",
      "Ordinal-encoding transactionType instead of OHE...\n",
      "Not using one-hot-encoding for \"transactionType\" since even a 5-valued categorical feature requires 55GB!\n",
      "Ordinal-encoding acqCountry instead of OHE...\n",
      "Not using one-hot-encoding for \"acqCountry\" since even a 5-valued categorical feature requires 55GB!\n",
      "Ordinal-encoding merchantCategoryCode instead of OHE...\n",
      "Not using one-hot-encoding for \"merchantCategoryCode\" since even a 5-valued categorical feature requires 55GB!\n",
      "Ordinal-encoding posConditionCode instead of OHE...\n",
      "Not using one-hot-encoding for \"posConditionCode\" since even a 5-valued categorical feature requires 55GB!\n",
      "Ordinal-encoding merchantCountryCode instead of OHE...\n",
      "Not using one-hot-encoding for \"merchantCountryCode\" since even a 5-valued categorical feature requires 55GB!\n",
      "Ordinal-encoding merchantName instead of OHE...\n",
      "Not using one-hot-encoding for \"merchantName\" since even a 5-valued categorical feature requires 55GB!\n",
      "Caching the scaling-transformation objects at: models//categorical_cols_encoders.pickle...\n",
      "Scaling down column `creditLimit`...\n",
      "Training a MinMaxScaler() for column `creditLimit`\n",
      "Scaling down column `availableMoney`...\n",
      "Training a MinMaxScaler() for column `availableMoney`\n",
      "Caching the scaling-transformation objects at: models//numerical_col_scalers.pickle...\n",
      "Dropping ['transactionDateTime', 'currentExpDate', 'accountOpenDate', 'dateOfLastAddressChange', 'cardCVV', 'enteredCVV', 'transactionDtDate', 'accountOpenDtDate', 'lastAddressChangeDtDate']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils.util_functions import read_zip_file_as_df, levenshtein_distance, add_time_dependent_features, drop_unary_columns, impute_transactionType\n",
    "from utils.util_functions import get_reversals_report, get_multiswipe_transactions, display_class_imbalance, convert_boolean_to_int\n",
    "from utils.util_functions import encode_categorical_cols, drop_irrelevant_columns, scaledown_numerical_cols, print_neat_metrics\n",
    "from utils.util_functions import train_random_forest_classifier\n",
    "\n",
    "from config_params.config import SRC_DIR_NAME, TGT_FILE_NAME, SRC_ZIP_FILE, MODEL_PATH, PARAM_GRID, TGT_DIR_NAME\n",
    "\n",
    "\n",
    "\n",
    "df = read_zip_file_as_df(dir_name=SRC_DIR_NAME, zipfile_name=SRC_ZIP_FILE, tgt_filename=TGT_FILE_NAME)\n",
    "\n",
    "\n",
    "# Engineer date-time features from the input datetime column and drop the original column\n",
    "df['transactionDt'] = pd.to_datetime(df['transactionDateTime'])\n",
    "df = add_time_dependent_features(df, 'transactionDt', True)\n",
    "\n",
    "df['accountOpenDt'] = pd.to_datetime(df['accountOpenDate'])\n",
    "df = add_time_dependent_features(df, 'accountOpenDt')\n",
    "\n",
    "df['lastAddressChangeDt'] = pd.to_datetime(df['dateOfLastAddressChange'])\n",
    "df = add_time_dependent_features(df, 'lastAddressChangeDt')\n",
    "\n",
    "\n",
    "# Rather than just binary non-equality, check score of mismatch: a single digit wrong might be just a minor blunder\n",
    "df = df.astype({'cardCVV':'str', 'enteredCVV':'str'})\n",
    "df['cvvMismatchScore'] = df.apply(lambda x : levenshtein_distance(x['enteredCVV'], x['enteredCVV']), axis=1)\n",
    "\n",
    "\n",
    "# Some basic cleansing/preprocessing logic\n",
    "main_df = df.copy(deep=True)\n",
    "main_df = drop_unary_columns(main_df, verbose=True)\n",
    "main_df = impute_transactionType(main_df, verbose=True)\n",
    "\n",
    "# Fetch the report of reversal-transactions\n",
    "report_reversals_df = get_reversals_report(main_df)\n",
    "report_reversals_df.to_csv(f'{TGT_DIR_NAME}/Report_Reversals.csv', index=False)\n",
    "\n",
    "# Fetch the report of multiswipe-transactions\n",
    "multiswipes_df = get_multiswipe_transactions(main_df)\n",
    "multiswipes_df.to_csv(f'{TGT_DIR_NAME}/Report_Multiswipes.csv', index=False)\n",
    "\n",
    "\n",
    "# Log the class-imbalance within our current dataset\n",
    "display_class_imbalance(main_df)\n",
    "\n",
    "# Convert the boolean columns to integer-type\n",
    "main_df = convert_boolean_to_int(main_df, verbose=True)\n",
    "\n",
    "# Apply Ordinal-Encoding to each of cat-column and keep track of the transformations\n",
    "main_df, categorical_cols_encoders = encode_categorical_cols(main_df, model_path=MODEL_PATH, verbose=True)\n",
    "\n",
    "# Apply Scaling to each of cat-column and keep track of the transformations\n",
    "main_df, numerical_col_scalers = scaledown_numerical_cols(main_df, model_path=MODEL_PATH, verbose=True)\n",
    "\n",
    "# Drop off the irrelevant non-numerical columns now\n",
    "main_df = drop_irrelevant_columns(main_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\HP\\AppData\\Local\\Temp\\ipykernel_18816\\708854427.py:4: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  features = main_df[feature_cols]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    }
   ],
   "source": [
    "# Create the train-test split of features and labels\n",
    "feature_cols = set(main_df.columns) - set(['isFraud', 'cardCVV', 'enteredCVV', 'cardLast4Digits', 'accountNumber', 'customerId'])\n",
    "labels = main_df['isFraud']\n",
    "features = main_df[feature_cols]\n",
    "x_train, x_test, y_train, y_test = train_test_split(features, labels, test_size=0.1, stratify=labels)\n",
    "\n",
    "# Apply grid-search-cv for a random-forest-classifier and cache the model\n",
    "model = train_random_forest_classifier(x_train, y_train, param_grid=PARAM_GRID, model_path=MODEL_PATH)\n",
    "\n",
    "# Print out the model's evaluation metrics\n",
    "preds = model.predict(x_test)\n",
    "print_neat_metrics(expected=y_test, preds=preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision = 99.02%.\n",
      "Recall = 8.13%.\n",
      "Accuracy = 98.55%.\n",
      "F1 score = 15.03%.\n",
      "Confusion matrix for Random-Forest model = \n",
      "\tTP=101  FN=1141\n",
      "\tFP=1  TN=77394\n",
      "\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
